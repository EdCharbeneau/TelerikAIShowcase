@using System.Globalization
@inject ISpeechRecognitionService SpeechRecognition
@implements IDisposable

@if (isRecording)
{
    <TelerikButton Id="@Id" Title="Stop Recording" OnClick="OnStopRecording"
    ThemeColor="@(ThemeConstants.Button.ThemeColor.Error)"
    FillMode="@(ThemeConstants.Button.FillMode.Solid)">
        <TelerikLoader Type="@LoaderType.Pulsing"
        ThemeColor="@(ThemeConstants.Button.ThemeColor.Inverse)"
        Size="@(ThemeConstants.Loader.Size.Small)"
        Visible="isRecording" />
        <TelerikSvgIcon Icon="SvgIcon.RadiobuttonChecked"
        Size="@(ThemeConstants.SvgIcon.Size.ExtraLarge)" />
    </TelerikButton>
}
else
{
    <TelerikButton Id="@Id" Title="Record" OnClick="OnRecordClicked"
    ThemeColor="@(ThemeConstants.Button.ThemeColor.Error)"
    FillMode="@(ThemeConstants.Button.FillMode.Outline)">
        <TelerikSvgIcon Icon="SvgIcon.RadiobuttonChecked"
        Size="@(ThemeConstants.SvgIcon.Size.ExtraLarge)" />
    </TelerikButton>
}

@code {

    IDisposable? _recognitionSubscription;
    bool isRecording;

    [Parameter]
    public string? Id { get; set; }

    [Parameter]
    public EventCallback<string> OnRecongizeded { get; set; }

    [Parameter]
    public EventCallback<string> OnStarted { get; set; }

    [Parameter]
    public EventCallback<string> OnEnded { get; set; }

    [Parameter]
    public EventCallback<SpeechRecognitionErrorEvent> OnError { get; set; }

    [Parameter]
    public EventCallback<MouseEventArgs> OnRecordClick { get; set; }

    private Task OnRecordClicked(MouseEventArgs args)
    {
        if (OnRecordClick.HasDelegate)
        {
            return OnRecordClick.InvokeAsync();
        } else
        {
            return OnRecord();
        }
    }

    /// <summary>
    /// Defaults to CultureInfo.CurrentCulture.TwoLetterISOLanguageName
    /// </summary>
    [Parameter]
    public string Culture { get; set; } = CultureInfo.CurrentCulture.TwoLetterISOLanguageName;

    Task OnRecognizedHandler(string recognizedText) => OnRecongizeded.InvokeAsync(recognizedText);

    public Task StartRecording() => OnRecord();

    async Task OnRecord()
    {
        if (isRecording) await SpeechRecognition.CancelSpeechRecognitionAsync(true);
        _recognitionSubscription?.Dispose();
        _recognitionSubscription = await SpeechRecognition.RecognizeSpeechAsync(Culture,
           onError: OnErrorHandler,
           onRecognized: OnRecognizedHandler,
           onStarted: OnStartedHandler,
           onEnded: OnEndedHandler);
    }

    async Task OnStopRecording() => await SpeechRecognition.CancelSpeechRecognitionAsync(true);

    async Task OnEndedHandler()
    {
        await OnEnded.InvokeAsync();
        isRecording = false;
        StateHasChanged();
    }

    async Task OnStartedHandler()
    {
        await OnStarted.InvokeAsync();
        isRecording = true;
        StateHasChanged();
    }

    Task OnErrorHandler(SpeechRecognitionErrorEvent args)
    {
        if (OnError.HasDelegate)
        {
            return OnError.InvokeAsync(args);
        }
        return DefaultErrorHandler(args);
    }

    Task DefaultErrorHandler(SpeechRecognitionErrorEvent args)
    {
        switch (args.Error)
        {
            case "audio-capture":
            case "network":
            case "not-allowed":
            case "service-not-allowed":
            case "bad-grammar":
            case "language-not-supported":
                throw new Exception($"Speech: {args.Error}: {args.Message}");
            case "no-speech":
            case "aborted":
                break;
        };
        StateHasChanged();
        return Task.CompletedTask;
    }

    public void Dispose() => _recognitionSubscription?.Dispose();

}
